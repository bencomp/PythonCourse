{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< [NTLK](https://tdm.universiteitleiden.nl/Python/NLTK.html) | [Table of contents](https://tdm.universiteitleiden.nl/Python) | [Data visualisation with matplotlib](https://tdm.universiteitleiden.nl/Python/Visualisation.html) >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analyses with pandas\n",
    "\n",
    "'Pandas' is a Python library which was developed for the manipulation and the analysis of data sets. It is available for Python version 2.7 and higher. The name of the library loosely stands for “Python Data Analysis Library”. Pandas contains methods that enable programmers to read data from and write data to a wide range of file formats, including CSV, TSV, Excel spreadsheets and MySQL databases, and it offers numerous statistical methods that can be used to analyse these data.\n",
    "\n",
    "If pandas has been installed successfully on your computer, this library can be imported into your program using the `import` keyword.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As can be seen, this import statement also assigns an alias, namely `pd`. This is a short code for the library. After this point, the library can be referred to using this brief code. Without this alias, the full name `pandas` would have to be typed in each time a method from this library is needed.\n",
    "\n",
    "\n",
    "## Reading a CSV file\n",
    "\n",
    "If your data set is stored in the csv format, it can be accessed using the `read_csv()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv( 'data.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that are read from the csv file are represented as a specific data structure which is known within the context of pandas as a data frame. A data frame can be compared to a regular table in a database. It consists of rows and columns. In the code above, the data frame is stored in a variable named `df`.\n",
    "\n",
    "As is indicated by the name of the file format, CSV files conventionally separate the individual values in the data set using commas. In some cases however, such files may also work with other types of separators, such as hyphens or semi-colons. In the `read_csv()` method, it is also possible to specify the separator, i.e. the character that must be used to separate the row into individual values. For more information, see the [guide on `read_csv()`](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-read-csv-table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv( 'data.csv' , sep = ';' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data set includes floating point numbers, it can also be useful to indicate the character to be used as a decimal point, via the `decimal` parameter. Floating point numbers are typically represented using either the period or the comma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv( 'data.csv' , decimal = '.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading an Excel spreadsheet\n",
    "\n",
    "The Pandas library also offers a method named `read_excel()`. You can use this function to process data stored in an Excel spreadsheet. The method needs to be used with two parameters. The first parameter is simply the name of the Excel file that you want to work with. Secondly, as a value to a parameter named `sheet_name`, you need to provide the name of the sheet that you want to read. Similarly to the way in which `read_csv()` processes data, `read_excel()` loads the data on the sheet that you mention into a data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel( 'Data.xlsx' , sheet_name = \"Sheet1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic analyses\n",
    "\n",
    "Once a data frame has been created, the data set can be examined using a number of methods that are available within the Pandas library. These methods will be explained using the simple data set shown below:\n",
    "\n",
    "```\n",
    "A,B,C,D\n",
    "12,5,6,12\n",
    "14,11,17,20\n",
    "15,6,8,19\n",
    "8,3,21,5\n",
    "10,9,14,7\n",
    "```\n",
    "\n",
    "\n",
    "The `head()` method, firstly, prints the first few rows of the data frame. If no integer is provided within the parentheses, Pandas will show five rows by default. The number of rows to be shown can be specified, however, within the parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv( 'data.csv' )\n",
    "\n",
    "print( df.head(2) )  \n",
    "# This will print the first two records of the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shape` property returns information about the number of rows and columns. Note that `shape` needs to be used without parentheses (because it is a property and not a method).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values that can be seen on the very first line of the sample csv file that was discussed above function as a header. After the creation of the data frame, using `read_csv()`, the strings that occur in this header, and which are delimited by commas, become available as column names. \n",
    "\n",
    "You can request an overview of all the column names using the `columns` property. For the sake of readability, the Index object that generated by this property is converted to a list.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column headings:\")\n",
    "print( list( df.columns) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "The values in a column of a data frame can be accessed separately using the name of the column. This assumes, obviously, that such column names have been defined. In order to obtain the data in a specific column, the name of the column must be appended to the name of the data frame using square brackets, as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df['A']  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above will print all the values in the column named 'A'. Within the context of Pandas, this list of values is referred to as a Series. This data structure is very similar to a regular Python list. An important difference between lists and Series is that, in the latter data structure, the individual values actually consist of two values: (1) the actual items and (2) the indices of these items. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical functions\n",
    "\n",
    "Within Pandas, you can use methods such as `max()`, `min()`, `mean()` to receive basic statistical information about numerical values in your data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df['A'].max() )\n",
    "## max() identifies the highest number within the column that is mentioned within the square brackets.\n",
    "\n",
    "print( df['B'].min() )\n",
    "# min() identifies the lowest number\n",
    "\n",
    "print( df['C'].mean() )\n",
    "# mean() calculates the mean of all the values in a specific column\n",
    "\n",
    "print( df['D'].sum() )\n",
    "## sum() performs an addition of all the numbers in a column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to perform statistical analyses on all the columns of the dataframe, you can also append the name of the needed method directly to the data frame variable, without specifying a column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df.sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating through a data frame\n",
    "\n",
    "To view all the rows in a data frame, you can make use of the `iterrows()` method. This method processes the data frame row by row, and returns a new Series for each row it finds in the data frame. In the code below, the individual Series that represents a row with values from all the columns on that row is given the name `row`. When the variable name `row` is used in combination with a column name, this will represent the data in that particular column. The method `iterrows()` can also return the index of each row, but that index is not actually used in the fragment that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv( 'data.csv' )\n",
    "\n",
    "for index , row in df.iterrows():\n",
    "    print( row['B'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting subsets\n",
    "\n",
    "We have seen how you can select columns by their name, like `df['A']`. In many situations you will want to select a subset of rows using filter criteria. Pandas offers various ways of filtering.\n",
    "\n",
    "### Filtering by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using numeric index values, just like rows. But you need to add `.iloc` to differentiate from selecting columns\n",
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First rows\n",
    "df.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows and columns by number\n",
    "df.iloc[1:3, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by values\n",
    "\n",
    "Filtering rows by the values they have for certain columns is perhaps even more useful than filtering by index values.\n",
    "\n",
    "One of the ways to do this is using the `query()` method, which takes a string representing a query as its parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows with column B values over 5\n",
    "df.query('B > 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('(A+B) > 20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is using *boolean indexing*. From [the pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing):\n",
    "\n",
    "> Another common operation is the use of boolean vectors to filter the data. The operators are: `|` for `or`, `&` for `and`, and `~` for `not`. These must be grouped by using parentheses, since by default Python will evaluate an expression such as `df.A > 2 & df.B < 3` as `df.A > (2 & df.B) < 3`, while the desired evaluation order is `(df.A > 2) & (df.B < 3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This expression creates a boolean Series with `True` for rows in which the expression holds\n",
    "df['A'] + df['B'] > 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The boolean Series can be used to select the correct rows. This is equivalent to the second `query()` example above.\n",
    "df[df['A'] + df['B'] > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by not-missing values using `notna()`\n",
    "df[df.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using values in calculations\n",
    "\n",
    "One of the strengths of Pandas is its speed when working with full columns. For example, you can use Series and even DataFrames in calculations like addition, subtraction and multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the values of columns A and B pairwise\n",
    "df['A'] + df['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply all values in the data frame by 2\n",
    "2 * df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the same number 3 to all values in column D\n",
    "df['D'] + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping items and aggregation\n",
    "\n",
    "Pandas also offers a method named `groupby()` which can be very useful when your data set contains labels or categories for specific records. Using `groupby()`, the records which have been assigned the same category can all be placed in a single group. Subsequently, it becomes possible to perform calcutions for each group that has been created. This process is demonstrated below.  \n",
    "\n",
    "The following line firstly assigns categories to the five records in the data set. It does this by adding a columns to the existing data frame named `df`. The number of items in the list that is assigned to the new column, named `class`, needs to be identical to the number of rows in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = [ 'Category1' , 'Category1' , 'Category2' , 'Category2' , 'Category2'  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these labels have been assigned, the name of the column containing these labels can be used as a parameter for `groupby()`. The method then creates the various groups, based on the values it find in the column that is mentioned. Once the groups have been established, you can apply statistical functions such as `mean()`, `sum()` or `max()` to each of these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('class').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can also group by the values of multiple columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subclass'] = [ 'Class1', 'Class2', 'Class1', 'Class2', 'Class2']\n",
    "df.groupby( [ 'class', 'subclass' ] ).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< [NTLK](https://tdm.universiteitleiden.nl/Python/NLTK.html) | [Table of contents](https://tdm.universiteitleiden.nl/Python) | [Data visualisation with matplotlib](https://tdm.universiteitleiden.nl/Python/Visualisation.html) >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
