{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data acquisition - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.1.\n",
    "\n",
    "The list below contains a number of URLs. They are the web addressed of texts created for the Project Gutenberg website.   \n",
    "\n",
    "```\n",
    "urls = [ 'http://www.gutenberg.org/files/580/580-0.txt' ,\n",
    "'http://www.gutenberg.org/files/1400/1400-0.txt' ,\n",
    "'http://www.gutenberg.org/files/786/786-0.txt' ,\n",
    "'http://www.gutenberg.org/files/766/766-0.txt' \n",
    "]\n",
    "```\n",
    "\n",
    "Write a program in Python which can download all the files that are listed. As filenames, use the same names that are used by Project Gutenberg (e.g. '580-0.txt' or '1400-0.txt'). The basename in a URL can be extracted using the `os.path.basename()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os \n",
    "\n",
    "# Create the list\n",
    "urls = [  \n",
    "]\n",
    "\n",
    "# Download and store the texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.2.\n",
    "\n",
    "Write Python code which can download the titles and the URLs of Wikipedia articles whose titles contain the word 'Dutch'. Your code needs to display the first 30 results only.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "baseURL = 'https://en.wikipedia.org/w/api.php?action=opensearch'\n",
    "\n",
    "# Get the search results and display them\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.3.\n",
    "\n",
    "Write an application in Python which can extract all the publications that have been added to a specific ORCID account. Make use of the ORCID API to do this. Information about individual ORCID accounts can be obtained by appending these to the following base URL: https://pub.orcid.org/v2.0/. The ORCID API returns data in XML. The list of publications can be found underneath \"record/activities-summary/works/group\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose an ORCID to look up, e.g. 0000-0002-8469-6804\n",
    "orcid = ''\n",
    "\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "ns = {'o': 'http://www.orcid.org/ns/orcid' ,\n",
    "'s' : 'http://www.orcid.org/ns/search' ,\n",
    "'h': 'http://www.orcid.org/ns/history' ,\n",
    "'p': 'http://www.orcid.org/ns/person' ,\n",
    "'pd': 'http://www.orcid.org/ns/personal-details' ,\n",
    "'a': 'http://www.orcid.org/ns/activities' ,\n",
    "'e': 'http://www.orcid.org/ns/employment' ,\n",
    "'c': 'http://www.orcid.org/ns/common' , \n",
    "'w': 'http://www.orcid.org/ns/work'}\n",
    "\n",
    "# We expect that there may be an error and therefore use `try` and `except`\n",
    "try:\n",
    "    # Construct the API call\n",
    "    orcidUrl = \"https://pub.orcid.org/v2.0/\" + orcid\n",
    "    print( orcidUrl )\n",
    "    \n",
    "    # Find and print the record creation date\n",
    "    \n",
    "    \n",
    "    # Find and print the titles of the publications\n",
    "\n",
    "            \n",
    "except:\n",
    "    print(\"Data could not be downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 9.4.\n",
    "\n",
    "The API developed by [OpenStreetMap](https://www.openstreetmap.org/) can be used, among other things, to find the precise geographic coordinates of a specific location. The base URL of this API is https://nominatim.openstreetmap.org/search. Following the 'q' parameter, you need to supply a string describing the locations whose latitude and longitude you want to find. As values for the 'format' parameter, you can use 'xml' or 'json'. Use this API to find the longitude and the latitude of the addresses in the following list:\n",
    "\n",
    "```\n",
    "addresses = ['Grote Looiersstraat 17 Maastricht' ,\n",
    "'Witte Singel 27 Leiden' ,\n",
    "'Singel 425 Amsterdam' ,\n",
    "'Drift 27 Utrecht' ,\n",
    "'Broerstraat 4 Groningen']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "# Create the list of addresses\n",
    "addresses = []\n",
    "\n",
    "# Look up the latitude and longitude\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.5.\n",
    "\n",
    "Extract the titles of all the movies which are included on the [list of top rated movies](https://www.imdb.com/chart/top?ref_=ft_250) using web scraping. Also extract the URLs of the webpage on IMDB describing the individual movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
